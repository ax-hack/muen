<doc name="Muen Separation Kernel">
 <author>Adrian-Ken Rüegsegger, Reto Bürki</author>
 <version>0.1</version>

 <latex_preamble>
  \usepackage{acronym}
  \usepackage{pgfgantt}

  \begin{tikzfadingfrompicture}[name=flow fade]
   \shade[left color=transparent!0,
           right color=transparent!60] (0,0) rectangle (2,2);
  \end{tikzfadingfrompicture}
  \input{tikzstyle}
 </latex_preamble>

 <section id="introduction" label="Introduction" priority="0">
  <text priority="0">
   This document describes the Muen Separation Kernel (SK). It is intended to
   provide information and ultimately give a better understanding of the SK
   design and its implementation. Additionally a short overview of related
   topics such as system policy and integration is given. References for
   further reading are included as well.

   The reader is expected to be familiar with concepts related to system-level
   software such as Operating Systems/Microkernels, component-based systems as
   well as software development.

   The majority of this document is generated based on annotations in the SK
   source code\footnote{Version: //{str:SK.Version.Version_String}}.
  </text>
  <section id="intro_structure" label="Document structure" priority="0">
   <text priority="0">
    First, a high-level overview of the design, architecture and basic operation
    of the Muen Separation Kernel is provided.
    Description of the document structure.
   </text>
  </section>
 </section>

 <section id="overview" label="Overview" priority="0">
  <text priority="0">
   This section gives an overview of the design and architecture of the Muen
   Separation Kernel.
  </text>
  <section id="overview_architecture" label="System Architecture" priority="0">
   <text priority="0">
    Muen is an open-source Separation Kernel implemented in the SPARK
    programming language, which has been shown to be free from certain bug
    classes through the application of formal methods. It leverages the
    virtualization extensions provided by the hardware platform to securely
    isolate subjects and devices.

    \begin{figure}[ht]
     \centering
     \input{graph_arch}
     \label{fig-muenarch}
     \caption{Execution of VMs and native Subjects on top of the Muen SK. The
      Kernel is the only software running in the privileged Intel VT-x root mode
       while all Subjects execute in unprivileged non-root mode.}
    \end{figure}

    The formally proven Muen SK is the only part of the system running in VMX
    root mode: all subjects, be it fully-fledged VMs or small, native subjects,
    execute with lower privileges in non-root mode. By design, no code is
    executed in user-space (ring 3) of VMX root mode. This enables Muen to
    completely forgo code for handling Syscalls/Ring-3-to-Ring-0 transitions,
    significantly reducing the code size and complexity.

    Deterministic runtime behavior of the SK is achieved by avoiding
    long-running code paths and no preemption of kernel code. During kernel
    execution, external interrupts are disabled and the proof of absence of
    runtime errors assures that no exceptions occur. Furthermore, the absence of
    any kind of dynamic resource management and the fixed, cyclic scheduler
    contribute to highly deterministic runtime behavior of the kernel.

    The sole purpose of the kernel is to provide temporal and spatial
    isolation for subjects running on top of it. By design, all non-essential
    functionality has been removed from the kernel. This results in a
    significant reduction of code size and complexity. Figure \ref{fig:sksubs}
    illustrates parts that usually make up an Operating System and the subset
    that is implemented by the Muen SK.

    \begin{figure}[ht]
     \centering
     \input{graph_sk0}
     \caption{Complexity reduction of Muen SK compared to a classical, monolithical Kernel.}
     \label{fig:sksubs}
    \end{figure}

    Since resource allocation is static, there is no need for resource
    management at runtime. Additionally, Muen does not provide a complex
    hypercall API as is almost always the case. Subjects can only trigger
    events, such as sending a signal to a specific subject, that have been
    defined in their entirety in the policy at integration time.  Virtualization
    events such as traps are not handled by the SK but instead reflected to
    components as specified in the policy.

    Static configuration also frees the kernel from any policy decisions: the
    runtime behavior is precisely specified in the system policy which, in turn,
    enables detailed analysis of the system prior to its execution.

    Further functionality must be implemented in unprivileged subjects. Complex,
    abstracted IPC mechanism, which are usually provided by classical
    microkernels, are not part of the Muen kernel.

    In addition to minimization of kernel functionality, care is also taken to
    ensure that the implementation is made as comprehensible and understandable
    as possible. In particular, the use of complicated algorithms or complex
    language constructs is deliberately avoided.
   </text>
  </section>
   <section id="overview_policy" label="Policy / Configuration" priority="0">
    <text priority="0">
     This section gives a short description of the Muen system policy and  how
     it relates to the kernel. A detailed description of the Muen System
     Specification can be found in the corresponding document
     \cite{muen:system-spec}.

     In the context of Muen, integration of a system is defined as the process
     of assembling an executable system image out of constituent parts, such as
     compiled kernel and subject code, generated data structures (e.g.
     page tables), etc following a system description.

     The configuration of a Muen system takes place during the integration by
     means of a \emph{policy} in XML format. The policy includes a declaration
     of all existing hardware resources of the target platform, the subjects to
     be executed with their assigned resources as well as the scheduling plan.
     The plan specifies exactly when a subject should run on which CPU and for
     how long.

     Information flows between subjects are defined in their entirety in the
     policy. So-called memory channels declare directional writer/reader
     relationships and assignment of physical memory or devices for shared
     usage is also possible. Unassigned resources are not available during
     runtime.

     From the information specified in the policy, the Muen toolchain in
     conjunction with $\tau$0 generates the actual configuration of the
     hardware, which is merely applied by the kernel at runtime. For example,
     the page tables for a subject are generated, which the kernel applies
     accordingly, when the associated subject is executed. The SK has no
     knowledge of the exact layout of the page tables and which memory areas are
     accessible to a subject. In fact, these data structures are not even mapped
     into the address space of the kernel since they remain static and do not
     need to be accessed.

     As part of the integration, numerous validations are carried out. Each
     check ensures a specific functional or security-relevant system property,
     such as for example accessibility of sensitive system memory to subjects.
     These properties can, where desirable, be manually audited or visualized.

    </text>
   </section>
   <section id="overview_operation" label="Kernel Operation" priority="0">
    <text priority="0">
     The Muen kernel has two main entry points: system initialization and the
     scheduler loop. Upon start of a system the kernel puts the CPU in the
     appropriate state by setting up the MMU and transitioning into VMX
     root-mode. After setting up the interrupt controllers and IOMMU, the
     initial subject is executed via VM-Entry after all CPU cores have setup
     everything and are ready. Detailed description of kernel initialization is
     given in section \ref{impl_kernel_init}.

     On VM-Exit the hardware invokes the scheduler subprogram since it has been
     set in the subject VMCS data structure. After handling the exit condition,
     execution of the next subject is started by performing a VM-entry. The
     kernel control-flow is illustrated by figure \ref{fig:kernel-operation}.

     \begin{figure}[h]
      \centering
      \input{graph_operation}
      \caption{Kernel control-flow}
      \label{fig:kernel-operation}
     \end{figure}
    </text>
   </section>
   <section id="overview_separation" label="Separation of Subjects" priority="0">
    <text priority="0">
     The kernel implements the communication policy by separating subjects
     spatially and temporally. It does not have to perform any policy decisions
     because it is static and does not change. Thus, the Muen SK can be seen as
     a policy enforcement engine.

     Spatial separation of main memory is enforced through the use of hardware
     memory protection (MMU and IOMMU). The corresponding page tables are made
     active whenever a subject is executed. As a consequence, subjects have only
     access to the memory resources assigned to them.
     Architectural state, such as processor and FPU registers, is saved to an
     associated memory region when subjects change. The state of the subject to
     be executed is completely restored.

     Access rights to model-specific registers (MSRs) as well as I/O ports of
     devices are determined via MSR and I/O bitmaps, see Intel SDM Vol. 3C,
     "24.6 VM-Execution Control Fields" \cite{intelsdm}.
     Unauthorized access is intercepted by the processor and the execution of
     the subject is interrupted.

     Device interrupts are also protected by hardware: by using interrupt
     remapping, devices can only generate the interrupt vectors assigned in the
     policy.

     Temporal isolation is implemented by the scheduler, described in section
     \ref{overview_scheduling}.
    </text>
   </section>
   <section id="overview_scheduling" label="Scheduling" priority="0">
    <text priority="0">
     This section presents the design and operation of the Muen kernel scheduler
     and the chosen scheduling algorithm.

     Scheduling is defined as the process of selecting a subject and giving it
     access to system resources for a certain amount of time.  The main resource
     is processor time, which enables a subject to execute instructions and
     perform its task.

     A key objective of the scheduler is to provide temporal isolation by
     preventing any interference between subjects. To achieve this, scheduling
     is done in a fixed, cyclic and preemptive manner according to a plan
     specified in the system policy.

     Subjects are executed for a fixed amount of time, before being forcefully
     preempted by the scheduler. Preemption means that regardless of what
     operations a subject is currently performing, its execution is suspended
     when the allotted time quantum has been consumed. Suspension means the
     current state like CPU register contents is saved to the data structure
     associated with the subject. After a subject has been suspended, the
     scheduler restores the state and executes the next subject for a given
     amount of time.

     Scheduling information is declared in a \emph{scheduling plan}. Such a plan
     is part of the policy and specifies in what order subjects are executed on
     which logical CPU and for how long (see \ref{Skp.Scheduling}). The task of
     the scheduler is to enforce a given scheduling regime.

     A scheduling plan is specified in terms of frames. A \emph{major frame}
     consists of a sequence of minor frames. When the end of a major frame is
     reached, the scheduler starts over from the beginning and uses the first
     minor frame in a cyclic fashion. This means that major frames are
     repetitive. A \emph{minor frame} specifies a subject and a precise amount
     of time. This information is directly applied and enforced by the scheduler.

     Figure \ref{fig:example-major-frame} illustrates the structure of a major
     frame.  The major frame consists of four minor frames. Minor frame 2 has
     twice the amount of ticks than the other minor frames, which have identical
     length. Time progresses on the horizontal axis from left to right.

     When the major frame starts, subject 1 is scheduled for the length of minor
     frame 1, followed by a switch to subject 2. After that the two subjects are
     again scheduled in alternating fashion.

     \begin{figure}[ht]
      \centering
      \input{graph_major_frame}
      \caption{Example major frame}
      \label{fig:example-major-frame}
     \end{figure}

     On systems with multiple logical CPUs, a scheduling plan must specify a
     sequence of minor frames for each processor core. For any given major
     frame, the sum of all minor frame time slices of a major frame must amount
     to the same time duration. In order for the cores to not run out of sync,
     all CPUs synchronize by means of a barrier prior to starting a new major
     frame. Additionally, CPUs that switch minor frames at the same time also
     synchronize the execution of the next minor frame.

     An example of a scheduling plan for multiple logical CPUs is depicted in
     figure \ref{fig:example-scheduling-plan}. It illustrates a system with two
     logical CPUs that execute various subjects indicated by different colors.

     \begin{figure}[ht]
      \centering
      \input{graph_scheduling_plan}
      \caption{Example scheduling plan}
      \label{fig:example-scheduling-plan}
     \end{figure}

     CPU0 is executing the same subject for the whole duration of the major
     frame. This could for example be the $\tau$0 subject executing on the
     bootstrap processor (BSP). The second CPU is executing two subjects (blue
     and green) in alternating order. As can be seen, subject green is granted
     more CPU cycles than subject blue. All CPUs of the system wait on a barrier
     at the beginning of a new major frame.  This guarantees that all logical
     CPUs of a system are in-sync when major frames change.

     Since a system performs diverse tasks with different resource requirements,
     there is a need for some flexibility with regards to scheduling. To provide
     this degree of freedom while keeping the kernel complexity low, multiple
     scheduling plans can be specified in the system policy. By defining a
     distinct plan for each anticipated workload in the policy, the scheduling
     regimes are fixed at integration time.

     The privileged subject $\tau$0 is allowed to elect and activate one of the
     scheduling plans. A global variable termed \emph{major frame index}
     designates the currently active scheduling plan (see
     \ref{SK.Tau0_Interface.New_Major}). Its value is exclusively written by
     the BSP while it is used by all cores to determine the currently active
     major frame.
    </text>
   </section>
   <section id="overview_interaction" label="Subject Interaction" priority="0">
    <text priority="0">
     Compared to applications or virtual machines running on classical kernels
     (e.g. monolithic or microkernel), subjects have very limited means to
     influence the overall system. Only the resources assigned in the policy are
     accessible and the interaction with the SK is limited to the following
     mechanisms. Subjects can trigger static events defined in the policy. If
     there is a valid event number, the kernel executes the action defined by
     the event. Invalid event numbers are ignored.

     When so-called \emph{traps} occur, e.g. access to an unauthorized memory
     region, a trap table also specified in the policy is consulted. Similar to
     handling of events, the defined action is executed.

     The last interaction option is the timer mechanism. Each subject can
     define an event number and a time at which the event should be triggered. At
     the beginning of each time slice, the kernel checks whether the timer
     belonging to the subject to be executed has expired. In this case, the event
     designated by the event number is treated in the same way as the regular
     event mechanism. The timer can thus be regarded as a delayed triggering of
     events.

     An important use case is running a subject that depends on a monitor
     subject for emulation of certain operations, e.g. serial device emulation.
     In this scenario, whenever a subject performs an operation that triggers a
     trap the policy specifies an event of mode \emph{switch} with the target
     being the monitor subject. This instructs the kernel to hand over execution
     to the monitor, in effect reflecting the trap. The monitor subject can then
     determine the cause for the trap based on the information available in the
     subject state that is mapped into the monitor's address space. It can then
     emulate the appropriate action by changing the subject's state and finally
     hand over execution back by triggering an event that has been specified in
     the policy to resume the origin subject.

     Through the use of the event mechanism, the vast majority of traps is
     handed over to a second subject to process.
    </text>
   </section>
   <section id="overview_covert_channels" label="Avoidance of Covert Channels" priority="0">
    <text priority="0">
     The simplicity of SKs enables the explicit consideration of the problem of
     cover channels. Such channels allow a collaborating sender/receiver pair to
     transfer information past the system's security mechanisms. Covert channels
     are classified as data or timing channels.

     In a data channel, information may for example be hidden in metadata, such
     as using individual memory bits in an unconventional manner. The information
     to be transmitted is encoded by means of these bits, the receiver knows the
     special coding and is able to extract the data.

     Time channels use temporal variance of operations to transmit information.
     The receiver measures this variance and can thereby extract data bits. If a
     particular operation can be carried out quickly, then this is e.g.
     interpreted as 1; otherwise a 0 is assumed.

     Data channels can be largely avoided or eliminated by careful assignment of
     resources to subjects in the system policy. On the other hand, timing
     channels require careful consideration of all shared resources and, in many
     cases, can olny be limited in capacity by means of a suitable system
     structure.

     Muen offers the possibility to provide subjects with an inaccurate time
     source, i.e. removing direct access to the Time-Stamp Counter (TSC). Due to
     the low temporal resolution, observing a side channel is made significantly
     more difficult and thus the achievable transmission rate in practice is
     greatly reduced. In addition, subjects are preferably only assigned a
     single CPU, which prevents them from easily constructing a high resolution
     time source. The timer mechanism also offers only limited accuracy, as
     timers are only evaluated at the beginning of a minor frame.

     Deterministic scheduling can be leveraged to ensure that the amount of
     shared hardware (e.g. L1 cache, Branch Predictor Cache, Translation
     Lookaside-Buffer, etc.) is reduced. By appropriate configuration, it can
     be guaranteed that two subjects are not running on the same physical CPU
     and/or not at the same time. If subjects are executed at different times,
     the observability of side channels and their bandwidth is limited since the
     sender and receiver must always alternate encoding and decoding of data.

     Furthermore, on Muen systems, Hyper-Threading is generally disabled because
     hardware threads share much more (micro-)architectural state than physical
     CPU cores.

     As a general rule, only the required resources with minimal rights are
     available to both the kernel as well as subjects. This topic is further
     expanded in section \ref{datamodel_multicore}.
    </text>
   </section>
  </section>

 <section id="datamodel" label="Data Model" priority="0">
  <section id="datamodel_multicore" label="Multicore Support" priority="0">
   <text priority="0">
    Modern computers have an increasing number of CPU cores per processor. To
    utilize the hardware to its full potential, the Muen SK provides Multicore
    support.

    In a multicore system, a physical CPU package provides more than one
    processor core in a single package. Additionally, systems equipped with
    Intel's Hyper-Threading Technology (HTT) have two or more \emph{logical
    CPUs} per core. A logical CPU is an execution unit of the processor that
    runs an application or a kernel process.

    Since HyperThreads located on the same CPU core share big parts of the
    micro-architectural state without effective means of isolation, Muen does
    not use HTT. It effectively disables HTT by only executing one hardware
    thread per physical CPU core.

    In MP systems, one processor termed \emph{bootstrap processor}(BSP) is
    responsible for system initialization, while the other processors, called
    \emph{application processors} (APs), wait for an initialization sequence as
    specified by Intel \cite{intelsdm}.

    At the basis of the multicore design is the symmetric execution of the
    kernel on each CPU core. This means that all cores execute an instance of
    exactly the same Muen kernel code. The only difference being, that the
    system bring up code is run exclusively by the BSP.

    An important aspect of Muen's multicore design is that subjects are pinned
    to a specific logical CPU. Subjects do not migrate between cores and are
    exclusively executed on the core defined by the associated subject
    specification in the system policy. This removes complexity from the kernel
    and the overall system by thwarting potential isolation issues which could
    be caused by the transfer of subjects and their state between cores. This
    design decision further simplifies the kernel implementation since no
    complex cross-core synchronization and migration algorithm has to be devised
    and implemented. Furthermore, each core can be restricted to only have
    access to the data structures associated with subjects it is designated to
    execute.

    Since each CPU executes a distinct instance of the Muen kernel, by default,
    all kernel data is CPU-local, meaning it is not shared between kernels
    running on different CPUs. Global data is shared explicitly and is
    designated as such by placing it in a dedicated section (.globaldata).

    Kernel data can be categorized as follows:
    \begin{itemize}
     \item CPU-local data
     \item CPU-local, subject-related data
     \item Global data, shared by all CPUs
    \end{itemize}

    The following sections provide explanations for each of the categories.
   </text>
  </section>
  <section id="datamodel_cpulocal" label="CPU-local data" priority="0">
   <text priority="0">
    Library level data structures without special aspects (e.g. address clauses)
    are private, meaning each CPU has their own, local copy. This is achieved by
    providing each CPU with separate copies of the necessary ELF binary sections
    (\texttt{.data} and \texttt{.bss}). Only the memory regions of sections
    belonging to a given CPU are mapped into the address space of that
    particular kernel.
   </text>
   <section id="datamodel_cpulocal_init" label="Initialization" priority="0">
    <text priority="0">
     Initialization is performed by each CPU during Elaboration via a call to
     adainit in the assembly startup code.
    </text>
   </section>
  </section>
  <section id="datamodel_local_subject" label="Local subject-related data" priority="0">
   <text priority="0">
    Data structures associated with subjects, such as subject state, are
    implemented as arrays where each element is associated with a particular
    subject. The global subject ID is used as an index into the array to link an
    element to a specific subject. The array elements are dimensioned to 4K so
    they can be mapped as independent memory pages.

    These arrays are placed at specific virtual memory addresses. Only the
    elements belonging to subjects executed by a given CPU are mapped into the
    address space of that particular kernel.
   </text>
   <section id="datamodel_local_subject_init" label="Initialization" priority="0">
    <text priority="0">
     Each element is initialized by the executing CPU when processing the
     \texttt{SK.Scheduler.Init\_Subject} procedure during system
     initialization.
    </text>
   </section>
  </section>
  <section id="datamodel_global" label="Global shared data" priority="0">
   <text priority="0">
    Some data is accessed by all CPUs. This data is located in a separate,
    distinct ELF section (\texttt{.globaldata}) which is backed by a single
    physical memory region, shared across all CPUs. Each kernel has a mapping of
    this region at the same memory location.

    Variable instances that are shared globally are placed in the ELF section
    \texttt{.globaldata} via use of the Ada \texttt{Linker\_Section} aspect.

    By convention affected variables are prefixed with \texttt{Global\_}.
   </text>
   <section id="datamodel_global_init" label="Initialization" priority="0">
    <text priority="0">
     Initialization is performed either via static initialization (if possible)
     or using explicit Initialization procedures that are only executed by a
     single CPU, i.e. the BSP.
    </text>
   </section>
  </section>
 </section>

 <section id="kernel_devices" label="Devices" priority="0">
  <text priority="0">
   This section describes what I/O devices the kernel uses and for what purpose.
  </text>
  <section id="kernel_devs_apic" label="Interrupt Controllers" priority="0">
   <text priority="0">
    This section describes how the kernel programs the PIC, APIC and I/O APIC.
   </text>
  </section>
  <section id="kernel_devs_iommu" label="IOMMU" priority="0">
   <text priority="0">
    This section describes how the kernel programs the IOMMU for device
    isolation, DMA and Interrupt remapping.
   </text>
  </section>
  <section id="kernel_devs_timer" label="Timer" priority="0">
   <text priority="0">
    Muen uses the VMX-preemption timer as the timing source to realize
    preemption of subjects when a minor frame expires. It is a per-CPU timer,
    which is programmed by writing a countdown value in the corresponding VMCS
    field. In VMX non-root mode, the VMX-preemption timer counts down at a rate
    proportional to the TSC and causes a VM-exit when the counter reaches zero.
    For further documentation see Intel SDM Volume 3C, "25.5.1 VMX-Preemption
    Timer".

    Note that Muen only supports systems that have the "Invariant TSC" feature,
    see Intel SDM Vol. 3B "17.17.1 Invariant TSC".
   </text>
  </section>
  <section id="kernel_devs_debug" label="Diagnostics" priority="0">
   <text priority="0">
    The debug build of the Muen SK provides additional debug information at
    runtime via a serial I/O device. This output can provide system integrators
    and developers with additional information, e.g. in an unexpected error case
    as the crash audit information is output via the I/O device on top of
    writing it to the audit memory region. Which hardware device the kernel
    uses for diagnostics is specified in the system policy.

    All debug output statements in the kernel are enclosed in \texttt{pragma
    Debug}. This has the effect that none of them are present in the release
    version of the kernel as they are automatically removed by the compiler.
   </text>
  </section>
 </section>

 <section id="verification_and_validation" label="Verification" priority="20">
  <text priority="0">
   This section describes the formal methods and techniques applied to the
   verification of Muen.
  </text>
  <section id="verification_spark" label="SPARK" priority="-10">
   <text priority="0">
    SPARK is the primary technology used for the formal verification of Muen and
    particularly trustworthy components such as $\tau$0. It enables data and
    information flow analysis as well as the proof of absence of runtime errors.
    The necessary proofs are produced by the SPARK GNATprove tools which in turn
    use automated theorem provers, like the Z3 SMT
    solver\footnote{\url{https://github.com/Z3Prover/z3}} for example.
    Application of the GNATprove tools guarantees that the SPARK language rules
    are adhered to at all time and that the analyzed source code is valid.

    The proof of advanced functional features is realized with the help of the
    interactive theorem prover
    Isabelle\footnote{\url{https://isabelle.in.tum.de}}. Abstract properties
    are formalized in Isabelle/HOL. These possibly complex, external
    specifications are linked to the SPARK implementation by so-called
    \emph{Ghost Code}. The GNATprove tool generates verification conditions in
    the Why3 language, which are imported into Isabelle by means of a driver.
    This way, the correspondence of the SPARK source code to an abstract, formal
    specification can be shown.

    The interaction of the tools used for the verification is shown
    schematically in figure \ref{fig:spark-toolchain}.

    \begin{figure}[ht]
     \centering
     \input{graph_spark}
     \caption{Toolchain for the verification of SPARK programs.}
     \label{fig:spark-toolchain}
    \end{figure}
   </text>
  </section>
 </section>

 <section id="acronyms" label="Acronyms" priority="1000.0">
  <text priority="0">
   \begin{acronym}
    \acro{APIC}[APIC]{Advanced Programmable Interrupt Controller}
    \acro{AP}[AP]{Application Processor}
    \acro{BSP}[BSP]{Bootstrap Processor}
    \acro{SK}[SK]{Separation Kernel}
   \end{acronym}
  </text>
 </section>

</doc>
